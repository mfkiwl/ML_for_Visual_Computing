{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fe2e110",
   "metadata": {},
   "source": [
    "# NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c2cd03",
   "metadata": {},
   "source": [
    "##### All algorithms were designed by Hyungjoo Kim and Dataset was provided by UCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77700fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from numpy.linalg import inv\n",
    "from numpy.random import randn\n",
    "from sklearn import svm\n",
    "from sklearn import datasets as skdataset\n",
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6246103e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.load('Data_IRIS&MNIST/IRIS/iris_train_labels.npy') # [2 1 1 0 2 2 2 0 1...] (96,)\n",
    "train_samp = np.load('Data_IRIS&MNIST/IRIS/iris_train_samples.npy') # (96,4) sepal length, sepal width, petal length, petal width.\n",
    "val_label = np.load('Data_IRIS&MNIST/IRIS/iris_val_labels.npy')\n",
    "val_samp = np.load('Data_IRIS&MNIST/IRIS/iris_val_samples.npy')\n",
    "# Class\n",
    "# Iris Setosa for label 0\n",
    "# Iris Versicolour label 1\n",
    "# Iris Virginica for label 2\n",
    "MNIST_train_label = np.load('Data_IRIS&MNIST/MNIST/mnist_train_labels.npy')\n",
    "MNIST_train_samp = np.load('Data_IRIS&MNIST/MNIST/mnist_train_samples.npy')  # (44800, 28*28)\n",
    "MNIST_val_label = np.load('Data_IRIS&MNIST/MNIST/mnist_val_labels.npy')\n",
    "MNIST_val_samp = np.load('Data_IRIS&MNIST/MNIST/mnist_val_samples.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08d7479",
   "metadata": {},
   "source": [
    "**Task 1: Devise a three-layer neural network with n hidden states and sigmoid activation for classification. Exaplain how many parameters this has in one sentence.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8aa1f",
   "metadata": {},
   "source": [
    "**Answer:** This task requires 3 layers neural network with 3 hidden states (Whh, Whx and Why) and these states are used by **4 parameters that represent hh + (input_size * h) + (output_size * h).** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fe921c",
   "metadata": {},
   "source": [
    "**Task 2: Provide the equation for the gradient using chain rule for the network in point a).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d164d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 100 # hidden size\n",
    "X = MNIST_train_samp   #(44800, 28*28)\n",
    "y = MNIST_train_label\n",
    "y = [[0, 1] if Y == 1 else (1, 0) for Y in y]   # make one hot\n",
    "y = np.array(y)\n",
    "\n",
    "Whh = randn(h, h) * 0.01    # (100, 100)\n",
    "Wxh = randn(X.shape[1], h) * 0.01  # (784, 100)\n",
    "Why = randn(h, y.shape[1]) * 0.01  # (100, 2)\n",
    "\n",
    "# forward_propagation\n",
    "XW = np.matmul(X, Wxh)\n",
    "hidden_1 = 1 / (1 + np.exp(-XW))\n",
    "\n",
    "hidden_1Whh = np.matmul(hidden_1, Whh)\n",
    "before_h2 = hidden_1Whh + XW\n",
    "hidden_2 = 1 / (1 + np.exp(-before_h2))\n",
    "\n",
    "hidden_2Whh = np.matmul(hidden_2, Whh)\n",
    "before_h3 = hidden_2Whh + XW\n",
    "hidden_3 = 1 / (1 + np.exp(-before_h3))\n",
    "\n",
    "y_preds = np.matmul(hidden_3, Why)  #(n, h) (h, 2)\n",
    "loss = np.square(y_preds - y).sum()\n",
    "\n",
    "# backward_propagation\n",
    "grad_y_preds = (y_preds - y) * 2.0  # n, 2\n",
    "grad_Why = np.matmul(hidden_3.T, grad_y_preds)  # (h, n) (n, 2) >> hidden_2\n",
    "grad_hidden_3 = np.matmul(grad_y_preds, Why.T)  # (n, 2) (2, h) >> nh\n",
    "grad_before_h3 = grad_hidden_3 * hidden_3 * (1 - hidden_3)   # (n, h)\n",
    "grad_hidden_2 = np.matmul(grad_before_h3, Whh.T)  #(n, h) (h, h) >> nh\n",
    "grad_Whh = np.matmul(hidden_2.T, grad_before_h3)  # (h, n) (n, h) >> (h, h)\n",
    "grad_X = np.matmul(grad_before_h3, Wxh.T)  # (n, h) (h, n) >> (n, n)\n",
    "grad_Wxh = np.matmul(X.T, grad_before_h3)  # (n, n) (n, h) >> (n, h)\n",
    "grad_before_h2 = grad_hidden_2 * hidden_2 * (1 - hidden_2)  # (n, h)\n",
    "grad_hidden_1 = np.matmul(grad_before_h2, Whh.T)  #(n, h)\n",
    "grad_Whh = grad_Whh + np.matmul(hidden_1.T, grad_before_h2)\n",
    "grad_Wxh = grad_Wxh + np.matmul(X.T, grad_before_h2)\n",
    "grad_Wxh = grad_Wxh + np.matmul(X.T, (grad_hidden_1 * hidden_1 * (1 - hidden_1))) # in, n * n\n",
    "# sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421be3b",
   "metadata": {},
   "source": [
    "**Task 3:Implement the binary classifier nnclass(examplesA, examplesB, testExamples) that is trained with\n",
    "your implementation of (stochastic) GD and your gradient function using the network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a983cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(): \n",
    "    def __init__(self, Whh, Wxh, Why):\n",
    "        self.Whh = Whh\n",
    "        self.Wxh = Wxh\n",
    "        self.Why = Why\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        self.X = X\n",
    "        self.XW = np.matmul(X, self.Wxh)\n",
    "        self.hidden_1 = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
    "        self.hidden_1_Whh = np.matmul(self.hidden_1, self.Whh)  # (n, h)\n",
    "        self.before_hidden_2 = self.hidden_1_Whh + self.XW  #(n, h)\n",
    "        self.hidden_2 = 1 / (1 + np.exp(-self.before_hidden_2))  # (n, h)\n",
    "        self.hidden_2_Whh = np.matmul(self.hidden_2, self.Whh)\n",
    "        self.before_hidden_3 = self.hidden_2_Whh + self.XW\n",
    "        self.hidden_3 = 1 / (1 + np.exp(-self.before_hidden_3))\n",
    "        self.y_preds = np.matmul(self.hidden_3, self.Why)   # (n, h) (h, 2)\n",
    "        \n",
    "        return self.y_preds\n",
    "    \n",
    "    def loss_function(self, y_preds, y):\n",
    "        self.y = y\n",
    "        self.loss = np.square(self.y_preds - self.y).sum()\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward_pass(self):\n",
    "        self.grad_y_preds = (self.y_preds - self.y) * 2.0\n",
    "        self.grad_Why = np.matmul(self.hidden_3.T, self.grad_y_preds)  # (h, n) (n, 2) >> hidden_2\n",
    "        self.grad_hidden_3 = np.matmul(self.grad_y_preds, self.Why.T)  # (n, 2) (2, h) >> nh\n",
    "        self.grad_before_h3 = self.grad_hidden_3 * self.hidden_3 * (1 - self.hidden_3)   # (n, h)\n",
    "        self.grad_hidden_2 = np.matmul(self.grad_before_h3, self.Whh.T)  #(n, h) (h, h) >> nh\n",
    "        self.grad_Whh = np.matmul(self.hidden_2.T, self.grad_before_h3)  # (h, n) (n, h) >> (h, h)\n",
    "        #self.grad_X = np.matmul(self.grad_before_h3, self.Wxh.T)  # (n, h) (h, n) >> (n, n)\n",
    "        self.grad_Wxh = np.matmul(self.X.T, self.grad_before_h3)  # (n, n) (n, h) >> (n, h)\n",
    "        self.grad_before_h2 = self.grad_hidden_2 * self.hidden_2 * (1 - self.hidden_2)  # (n, h)\n",
    "        self.grad_hidden_1 = np.matmul(self.grad_before_h2, self.Whh.T)  #(n, h)\n",
    "        self.grad_Whh = self.grad_Whh + np.matmul(self.hidden_1.T, self.grad_before_h2)\n",
    "        self.grad_Wxh = self.grad_Wxh + np.matmul(self.X.T, self.grad_before_h2)\n",
    "        self.grad_Wxh = self.grad_Wxh + np.matmul(self.X.T, (self.grad_hidden_1 * self.hidden_1 * (1 - self.hidden_1))) # in, n * n\n",
    "        \n",
    "def nnclass(examplesA, examplesB, testExamples):\n",
    "    # batch_size and learning parameters\n",
    "    a_num = len(examplesA)\n",
    "    b_num = len(examplesB)\n",
    "    batch = 128\n",
    "    a_batch = int(128 * (a_num / (a_num + b_num)))\n",
    "    b_batch = batch - a_batch\n",
    "    iterations = (a_num + b_num) // 128 + 1 if (a_num + b_num) % 128 != 0 else (a_num + b_num) // 128\n",
    "    hidden = 100  # hidden layer width\n",
    "    learning_rate = 0.0001\n",
    "    epochs = 50\n",
    "    \n",
    "    # Initialising\n",
    "    Whh = randn(h, h) * 0.01\n",
    "    Wxh = randn(examplesA.shape[1], h) * 0.01  # 784, 100\n",
    "    Why = randn(h, 1) * 0.01  # 100, 2\n",
    "    model = train(Whh, Wxh, Why)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(iterations):\n",
    "            if i == iterations - 1:\n",
    "                A_sub = examplesA[i * a_batch :]\n",
    "                B_sub = examplesB[i * b_batch :]\n",
    "            else:\n",
    "                A_sub = examplesA[i * a_batch : (i + 1) * a_batch]\n",
    "                B_sub = examplesB[i * b_batch : (i + 1) * b_batch]\n",
    "                \n",
    "            X = np.vstack([A_sub, B_sub])\n",
    "            y_zeros = (np.zeros(len(B_sub))[np.newaxis]).T\n",
    "            y_ones = (np.ones(len(A_sub))[np.newaxis]).T\n",
    "            y = np.vstack([y_ones, y_zeros])\n",
    "            \n",
    "            y_preds = model.forward_pass(X)\n",
    "            loss = (model.loss_function(y_preds, y))\n",
    "            model.backward_pass()\n",
    "            \n",
    "            # backward pass and optimizing\n",
    "            Whh -= learning_rate * model.grad_Whh\n",
    "            Wxh -= learning_rate * model.grad_Wxh\n",
    "            Why -= learning_rate * model.grad_Why\n",
    "        print(f\"{(epoch + 1)} / {epochs}, Loss value is: \", loss)\n",
    "        \n",
    "    # validation set\n",
    "    y_preds = model.forward_pass(testExamples)\n",
    "    y_preds = (y_preds >= 0.5) * 1\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37fa1b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 50, Loss value is:  5.895711381737013\n",
      "2 / 50, Loss value is:  5.11010494780861\n",
      "3 / 50, Loss value is:  4.719286612011189\n",
      "4 / 50, Loss value is:  4.210346113198342\n",
      "5 / 50, Loss value is:  4.126657504275382\n",
      "6 / 50, Loss value is:  3.7891906865701928\n",
      "7 / 50, Loss value is:  3.5259686955431517\n",
      "8 / 50, Loss value is:  3.168074993515801\n",
      "9 / 50, Loss value is:  3.0199498129762317\n",
      "10 / 50, Loss value is:  2.866354756260951\n",
      "11 / 50, Loss value is:  2.7541943611675266\n",
      "12 / 50, Loss value is:  2.697630782365632\n",
      "13 / 50, Loss value is:  2.8332786801906176\n",
      "14 / 50, Loss value is:  2.544982077952598\n",
      "15 / 50, Loss value is:  2.543363889894092\n",
      "16 / 50, Loss value is:  2.417878030799562\n",
      "17 / 50, Loss value is:  2.4169433069351287\n",
      "18 / 50, Loss value is:  2.4115334191271316\n",
      "19 / 50, Loss value is:  2.34456983698386\n",
      "20 / 50, Loss value is:  2.3237632462846944\n",
      "21 / 50, Loss value is:  2.262886053422734\n",
      "22 / 50, Loss value is:  2.161211281018425\n",
      "23 / 50, Loss value is:  2.0244883406622627\n",
      "24 / 50, Loss value is:  1.9628207712758206\n",
      "25 / 50, Loss value is:  1.9442233215189666\n",
      "26 / 50, Loss value is:  1.9402264550350448\n",
      "27 / 50, Loss value is:  1.8932855475085475\n",
      "28 / 50, Loss value is:  1.8814263694980724\n",
      "29 / 50, Loss value is:  1.8538651136917208\n",
      "30 / 50, Loss value is:  1.8177905581944906\n",
      "31 / 50, Loss value is:  1.7783445430892135\n",
      "32 / 50, Loss value is:  1.7441064693441546\n",
      "33 / 50, Loss value is:  1.697255884707714\n",
      "34 / 50, Loss value is:  1.6584717171174397\n",
      "35 / 50, Loss value is:  1.6276968479485148\n",
      "36 / 50, Loss value is:  1.5801253752341444\n",
      "37 / 50, Loss value is:  1.5091234416448858\n",
      "38 / 50, Loss value is:  1.4903988357389706\n",
      "39 / 50, Loss value is:  1.471457744769\n",
      "40 / 50, Loss value is:  1.451657705973587\n",
      "41 / 50, Loss value is:  1.4360213687601586\n",
      "42 / 50, Loss value is:  1.4138023865840113\n",
      "43 / 50, Loss value is:  1.3930115303819282\n",
      "44 / 50, Loss value is:  1.3787525923700377\n",
      "45 / 50, Loss value is:  1.3553882702339428\n",
      "46 / 50, Loss value is:  1.331218543905351\n",
      "47 / 50, Loss value is:  1.3085084364585076\n",
      "48 / 50, Loss value is:  1.2897598655962392\n",
      "49 / 50, Loss value is:  1.2712562286484703\n",
      "50 / 50, Loss value is:  1.2564605594836522\n",
      "Accuracy value is:  0.9955714285714286\n"
     ]
    }
   ],
   "source": [
    "train_one = (MNIST_train_samp[MNIST_train_label == 1])\n",
    "train_non_one = (MNIST_train_samp[MNIST_train_label != 1])\n",
    "predictions_1 = nnclass(train_one, train_non_one, MNIST_val_samp)\n",
    "ground_truth = MNIST_val_label\n",
    "ground_truth = [1 if y == 1 else 0 for y in ground_truth]\n",
    "print(\"Accuracy value is: \", accuracy_score(ground_truth, predictions_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f5f9a",
   "metadata": {},
   "source": [
    "**Task 4: Do an analysis how changes of n affect the accuracy with MNIST. Positive labels are assigned to digit 1 and negative samples to other digits. Write not longer than fifteen sentences. A table and / or plot is\n",
    "welcome.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966e865f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "class train(): \n",
    "    def __init__(self, input_dim, n):\n",
    "        self.Whh = randn(h, h) * 0.01  # (100, 100)\n",
    "        self.Wxh = randn(input_dim, h) * 0.01 #  (784, 100)\n",
    "        self.Why = randn(h, 1) * 0.01  #(100, 2)\n",
    "        self.grad_Whh = np.zeros(self.Whh.shape)\n",
    "        self.grad_Wxh = np.zeros(self.Wxh.shape)\n",
    "        self.n = n\n",
    "        self.h = [0] * n\n",
    "        self.grad_h = [0] * n\n",
    "        \n",
    "    def forward_pass(self, X):\n",
    "        self.X = X\n",
    "        self.XW = np.matmul(X, self.Wxh)\n",
    "        self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
    "        for i in range(self.n - 1):\n",
    "            self.before_hidden = np.matmul(self.h[i], self.Whh) + self.XW  # (n, h)\n",
    "            self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n",
    "        self.y_preds = np.matmul(self.h[-1], self.Why)  # (n, h) (h, 2)\n",
    "        \n",
    "        return self.y_preds\n",
    "                           \n",
    "    def loss_function(self, y_preds, y):\n",
    "        self.y = y\n",
    "        self.loss = np.square(self.y_preds - self.y).sum()\n",
    "        \n",
    "        return self.loss\n",
    "    \n",
    "    def backward_pass(self):\n",
    "        self.grad_y_preds = (self.y_preds - self.y) * 2.0   # (n, 2)\n",
    "        self.grad_Why = np.matmul(self.h[-1].T, self.grad_y_preds)  # (h, n) (n, 2) >> hidden_2\n",
    "        self.grad_h[-1] = np.matmul(self.grad_y_preds, self.Why.T)  # (n, 2) (2, h) >> nh\n",
    "        for i in range(self.n - 1):\n",
    "            self.grad_before_h = self.grad_h[-i - 1] * self.h[-i - 1] * (1 - self.h[-i - 1])   # (n, h)\n",
    "            self.grad_h[-i - 2] = np.matmul(self.grad_before_h, self.Whh.T)  #(n, h) (h, h) >> nh\n",
    "            self.grad_Whh += np.matmul(self.h[-i - 2].T, self.grad_before_h)  # (h, n) (n, h) >> (h, h)\n",
    "            self.grad_Wxh += np.matmul(self.X.T, self.grad_before_h)  # (n, n) (n, h) >> (n, h)\n",
    "            \n",
    "        self.grad_Wxh = self.grad_Wxh + np.matmul(self.X.T, (self.grad_h[0] * self.h[0] * (1 - self.h[0]))) # in, n * n\n",
    "        \n",
    "def nnclass(examplesA, examplesB, testExamples, n):\n",
    "    # batch_size and learning parameters\n",
    "    a_num = len(examplesA)\n",
    "    b_num = len(examplesB)\n",
    "    batch = 128\n",
    "    a_batch = int(128 * (a_num / (a_num + b_num)))\n",
    "    b_batch = batch - a_batch\n",
    "    iterations = (a_num + b_num) // 128 + 1 if (a_num + b_num) % 128 != 0 else (a_num + b_num) // 128\n",
    "    hidden = 100  # hidden layer width\n",
    "    learning_rate = 0.0001\n",
    "    epochs = 3\n",
    "    \n",
    "    # Initialising\n",
    "    input_dims = examplesA.shape[1]\n",
    "    n = n\n",
    "    model = train(input_dims, n)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(iterations):\n",
    "            if i == iterations - 1:\n",
    "                A_sub = examplesA[i * a_batch :]\n",
    "                B_sub = examplesB[i * b_batch :]\n",
    "            else:\n",
    "                A_sub = examplesA[i * a_batch : (i + 1) * a_batch]\n",
    "                B_sub = examplesB[i * b_batch : (i + 1) * b_batch]\n",
    "                \n",
    "            X = np.vstack([A_sub, B_sub])\n",
    "            y_zeros = (np.zeros(len(B_sub))[np.newaxis]).T\n",
    "            y_ones = (np.ones(len(A_sub))[np.newaxis]).T\n",
    "            y = np.vstack([y_ones, y_zeros])\n",
    "            \n",
    "            y_preds = model.forward_pass(X)\n",
    "            loss = (model.loss_function(y_preds, y))\n",
    "            model.backward_pass()\n",
    "            \n",
    "            # backward pass and optimizing\n",
    "            model.Whh -= learning_rate * model.grad_Whh\n",
    "            model.Wxh -= learning_rate * model.grad_Wxh\n",
    "            model.Why -= learning_rate * model.grad_Why\n",
    "        print(f\"{(epoch + 1)} / {epochs}, Loss value is: \", loss)\n",
    "        \n",
    "    # validation set\n",
    "    y_preds = model.forward_pass(testExamples)\n",
    "    y_preds = (y_preds >= 0.5) * 1\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae9dd1b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  5.979318658450309\n",
      "2 / 3, Loss value is:  5.726019403721526\n",
      "3 / 3, Loss value is:  5.832826609622479\n",
      "Accuracy value is:  0.9911428571428571 for n = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.998425083023923\n",
      "2 / 3, Loss value is:  5.6463530383573115\n",
      "3 / 3, Loss value is:  6.18876725777624\n",
      "Accuracy value is:  0.9895714285714285 for n = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.118331995007262\n",
      "2 / 3, Loss value is:  6.661888257287453\n",
      "3 / 3, Loss value is:  5.659985532208972\n",
      "Accuracy value is:  0.9901428571428571 for n = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.004737948532997\n",
      "2 / 3, Loss value is:  6.340923286020731\n",
      "3 / 3, Loss value is:  6.447536383797779\n",
      "Accuracy value is:  0.991 for n = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.055116025014176\n",
      "2 / 3, Loss value is:  6.425108303170878\n",
      "3 / 3, Loss value is:  6.227924971020729\n",
      "Accuracy value is:  0.9901428571428571 for n = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.321797310857083\n",
      "2 / 3, Loss value is:  5.329516900257527\n",
      "3 / 3, Loss value is:  5.158106995888094\n",
      "Accuracy value is:  0.9898571428571429 for n = 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.762369260267522\n",
      "2 / 3, Loss value is:  6.7410782628365675\n",
      "3 / 3, Loss value is:  5.790815471566203\n",
      "Accuracy value is:  0.9901428571428571 for n = 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.617513489883052\n",
      "2 / 3, Loss value is:  5.812519016471316\n",
      "3 / 3, Loss value is:  6.612671476686701\n",
      "Accuracy value is:  0.9904285714285714 for n = 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.477638672149377\n",
      "2 / 3, Loss value is:  5.125954266052716\n",
      "3 / 3, Loss value is:  5.446108015289759\n",
      "Accuracy value is:  0.9892857142857143 for n = 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.271953409191169\n",
      "2 / 3, Loss value is:  6.235465447767364\n",
      "3 / 3, Loss value is:  6.329997031069915\n",
      "Accuracy value is:  0.9907142857142858 for n = 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  6.05017708841966\n",
      "2 / 3, Loss value is:  6.35800003998343\n",
      "3 / 3, Loss value is:  5.773969416134753\n",
      "Accuracy value is:  0.9912857142857143 for n = 81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  5.636851576269255\n",
      "2 / 3, Loss value is:  7.044146817417235\n",
      "3 / 3, Loss value is:  6.351620750532439\n",
      "Accuracy value is:  0.9897142857142858 for n = 94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-dd70f8065fce>:17: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[0] = 1 / (1 + np.exp(-self.XW))  # (n, h)\n",
      "<ipython-input-9-dd70f8065fce>:20: RuntimeWarning: overflow encountered in exp\n",
      "  self.h[i + 1] = 1 / (1 + np.exp(-self.before_hidden))   # (n, h)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3, Loss value is:  5.82789809266329\n",
      "2 / 3, Loss value is:  6.921442680978842\n",
      "3 / 3, Loss value is:  6.332761710173156\n",
      "Accuracy value is:  0.9908571428571429 for n = 100\n"
     ]
    }
   ],
   "source": [
    "train_one = (MNIST_train_samp[MNIST_train_label == 1])\n",
    "train_non_one = (MNIST_train_samp[MNIST_train_label != 1])\n",
    "accuracy_list = []\n",
    "n_list = [1, 2, 3, 4, 9, 22, 38, 45, 63, 76, 81, 94, 100]\n",
    "for n in (n_list):\n",
    "    predictions_2 = nnclass(train_one, train_non_one, MNIST_val_samp, n)\n",
    "    accuracy = accuracy_score(ground_truth, predictions_2)\n",
    "    print(\"Accuracy value is: \", accuracy, f\"for n = {n}\")\n",
    "    accuracy_list.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7159455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_list, accuracy_list)\n",
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309fec3",
   "metadata": {},
   "source": [
    "|  n   |     Accuracy     \n",
    "|:----:|:----------------:|  \n",
    "|  1   |0.9911428571428571|\n",
    "|  2   |0.9895714285714285|\n",
    "|  3   |0.9901428571428571|\n",
    "|  4   |       0.991      |\n",
    "|  9   |0.9901428571428571|\n",
    "|  22  |0.9898571428571429|\n",
    "|  38  |0.9901428571428571|\n",
    "|  45  |0.9904285714285714|\n",
    "|  63  |0.9892857142857143|\n",
    "|  76  |0.9907142857142858|\n",
    "|  81  |0.9912857142857143|\n",
    "|  94  |0.9897142857142858|\n",
    "|  100 |0.9908571428571429|\n",
    "\n",
    "**Answer:** **As shown above the figure, the number of hidden states do not significantly affect the accuracy on the test.** Many layers or wide hidden size seems ideal to allow giving better results. However, these mean that can exercise and use more function for training or testing. If the neural network uses more functions, it is more complex, which results in overfitting to the data and spends lots of time. The number of data was given constant during this project and the number of data should be sufficient samples to train and test in the network to get higher accuracy if the hidden states increase. Therefore, the accuracy might depend on proper the number of hidden states (to avoid over/under-fitting) and also depend on the quality of the model, which means the quantity and size of the training sample or data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10408ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
